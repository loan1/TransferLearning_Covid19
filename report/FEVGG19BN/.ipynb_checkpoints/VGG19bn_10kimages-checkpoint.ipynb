{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: https://drive.google.com/file/d/18aMf57_1u2AWInnMB67s3Xku0sPzm28u/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B1. Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#for Data preprocessing and Augmentation\n",
    "import os\n",
    "from imutils import paths\n",
    "import cv2\n",
    "# import Augmentor\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#for reading and displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "#Pytorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#torchvision for pre-trained models\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "\n",
    "#for evaluating model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B2. Dữ liệu đầu vào"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Khởi tạo giá trị các tham số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "classes = ['Normal', 'Covid']\n",
    "num_classes = 2\n",
    "num_epochs = 15\n",
    "criterion = CrossEntropyLoss()\n",
    "CHECKPOINT_PATH = '../FEVGG19bn/FEVGG19bn1.pt'\n",
    "path_dataset = '/media/trucloan/Data/Research/TransferLearningVGG19bnCovid1910k_images/dataset10K_images/'\n",
    "\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Đường dẫn đến tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = path_dataset + 'NORMAL/'\n",
    "covid = path_dataset + 'COVID/'\n",
    "\n",
    "dir_normal = os.listdir(normal)\n",
    "dir_covid = os.listdir(covid)\n",
    "\n",
    "\n",
    "dict_data0 = {'path': normal, 'image_name': dir_normal, 'labels': 0}\n",
    "dict_data1 = {'path': covid, 'image_name': dir_covid, 'labels': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(dict_data0)\n",
    "df1 = pd.DataFrame(dict_data1)\n",
    "df = pd.concat([df0, df1])\n",
    "df.to_csv('./data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   path        10000 non-null  object\n",
      " 1   image_name  10000 non-null  object\n",
      " 2   labels      10000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 312.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data=train_test_split(df, test_size=0.2, random_state = 42, shuffle=True)\n",
    "train_data, val_data =train_test_split(train_data, test_size=0.2, random_state = 42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 1600 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Định nghĩa lớp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, transform):\n",
    "        self.transform = transform\n",
    "        self.csv = csv\n",
    "        \n",
    "        self.image_name = self.csv[:]['image_name']\n",
    "        self.label = np.array(self.csv[:]['labels'])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        images = Image.open(self.csv['path'].iloc[index] + self.image_name.iloc[index]).convert('RGB')\n",
    "        \n",
    "        images = self.transform(images)\n",
    "        targets = self.label[index]\n",
    "        targets = torch.tensor(targets, dtype = torch.long)\n",
    "#         sample = {'image': image, 'labels': targets}\n",
    "        \n",
    "        return images, targets\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Biến đổi và đưa dữ liệu vào mô hình huấn luyện theo batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ImageDataset at 0x7ff90b408590>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.Resize((224,224)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(train_data, transform)\n",
    "val_dataset = ImageDataset(val_data, transform)\n",
    "test_dataset = ImageDataset(test_data, transform)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B3. Định nghĩa hàm train model (sử dụng  Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, loss_list, acc_list):\n",
    "    model.to(device)\n",
    "    #List to store loss to visualize\n",
    "    lossli = loss_list\n",
    "    accli = acc_list\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    count = 0\n",
    "    patience = 8 # nếu val_loss tăng 15 lần thì ngừng\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        train_acc = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        \n",
    "        model.train()\n",
    "        for data, label in tqdm(train_dataloader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            \n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "            _, pred = torch.max(output, 1)              \n",
    "            \n",
    "            train_acc += pred.eq(label).sum().item()\n",
    "            \n",
    "#         scheduler.step() ###########\n",
    "            \n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, label in tqdm(val_dataloader):\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                valid_loss += loss.item()*data.size(0)\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, pred = torch.max(output, 1)\n",
    "#                 y_true += target.tolist()\n",
    "#                 y_pred += pred.tolist()  \n",
    "                \n",
    "                valid_acc +=  pred.eq(label).sum().item()\n",
    "       \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_dataloader.dataset)\n",
    "        valid_loss = valid_loss/len(val_dataloader.dataset)\n",
    "        lossli.append({'epoch':epoch,'train_loss': train_loss,'valid_loss':valid_loss})\n",
    "        \n",
    "        train_acc = train_acc*100/len(train_dataloader.dataset)\n",
    "        valid_acc = valid_acc*100/len(val_dataloader.dataset)\n",
    "        accli.append({'epoch':epoch,'train_acc': train_acc,'valid_acc':valid_acc})\n",
    "        \n",
    "        ####################\n",
    "        # Early stopping #\n",
    "        ##################\n",
    "        \n",
    "        # print training/validation statistics\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\n \\tTraining Acc: {:.6f} \\tValidation Acc: {:.6f}'.format(\n",
    "            epoch, train_loss, valid_loss, train_acc, valid_acc))\n",
    "        # save model if validation loss has decreased\n",
    "       \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_acc': accli,\n",
    "            'loss_list': lossli,\n",
    "            'loss': loss\n",
    "            }, CHECKPOINT_PATH)\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "            \n",
    "            count = 0\n",
    "            print('count = ',count)\n",
    "            torch.save(model, '../FEVGG19bn/FEVGG19bn_model.pt') #save model \n",
    "                                  \n",
    "            valid_loss_min = valid_loss\n",
    "        else:\n",
    "            count += 1\n",
    "            print('count = ',count)\n",
    "            if count >= patience:\n",
    "                print('Early stopping!')\n",
    "   \n",
    "                return lossli, accli    \n",
    "           \n",
    "    return lossli, accli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B4. Đặt thuộc tính .requires_grad của các tham số trong model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad (model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B5. Khởi tạo và reshape model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(num_classes, feature_extract, use_pretrained = True):\n",
    "    model_ft = models.vgg19_bn(pretrained = use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = 224\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained = True)\n",
    "\n",
    "print (model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B6. Sử dụng hàm tối ưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.0.weight\n",
      "\t features.0.bias\n",
      "\t features.1.weight\n",
      "\t features.1.bias\n",
      "\t features.3.weight\n",
      "\t features.3.bias\n",
      "\t features.4.weight\n",
      "\t features.4.bias\n",
      "\t features.7.weight\n",
      "\t features.7.bias\n",
      "\t features.8.weight\n",
      "\t features.8.bias\n",
      "\t features.10.weight\n",
      "\t features.10.bias\n",
      "\t features.11.weight\n",
      "\t features.11.bias\n",
      "\t features.14.weight\n",
      "\t features.14.bias\n",
      "\t features.15.weight\n",
      "\t features.15.bias\n",
      "\t features.17.weight\n",
      "\t features.17.bias\n",
      "\t features.18.weight\n",
      "\t features.18.bias\n",
      "\t features.20.weight\n",
      "\t features.20.bias\n",
      "\t features.21.weight\n",
      "\t features.21.bias\n",
      "\t features.23.weight\n",
      "\t features.23.bias\n",
      "\t features.24.weight\n",
      "\t features.24.bias\n",
      "\t features.27.weight\n",
      "\t features.27.bias\n",
      "\t features.28.weight\n",
      "\t features.28.bias\n",
      "\t features.30.weight\n",
      "\t features.30.bias\n",
      "\t features.31.weight\n",
      "\t features.31.bias\n",
      "\t features.33.weight\n",
      "\t features.33.bias\n",
      "\t features.34.weight\n",
      "\t features.34.bias\n",
      "\t features.36.weight\n",
      "\t features.36.bias\n",
      "\t features.37.weight\n",
      "\t features.37.bias\n",
      "\t features.40.weight\n",
      "\t features.40.bias\n",
      "\t features.41.weight\n",
      "\t features.41.bias\n",
      "\t features.43.weight\n",
      "\t features.43.bias\n",
      "\t features.44.weight\n",
      "\t features.44.bias\n",
      "\t features.46.weight\n",
      "\t features.46.bias\n",
      "\t features.47.weight\n",
      "\t features.47.bias\n",
      "\t features.49.weight\n",
      "\t features.49.bias\n",
      "\t features.50.weight\n",
      "\t features.50.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = Adam(params_to_update ,lr = 0.001, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B7. Chạy các bước huấn luyện và kiểm định mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:42<00:00,  1.23it/s]\n",
      "100%|██████████| 50/50 [00:33<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.331658 \tValidation Loss: 0.213740 \n",
      " \tTraining Acc: 90.671875 \tValidation Acc: 92.875000\n",
      "Validation loss decreased (inf --> 0.213740). Saving model ...\n",
      "count =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:43<00:00,  1.23it/s]\n",
      "100%|██████████| 50/50 [00:33<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.170686 \tValidation Loss: 0.283765 \n",
      " \tTraining Acc: 93.781250 \tValidation Acc: 89.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 164/200 [02:13<00:31,  1.16it/s]"
     ]
    }
   ],
   "source": [
    "loss_list, acc_list = [],[]\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "loss, acc = training_loop(\n",
    "    model = model_ft,\n",
    "    optimizer = optimizer,\n",
    "    loss_list = loss_list,\n",
    "    acc_list = acc_list\n",
    ")\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model, state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(CHECKPOINT_PATH)#, map_location=device)\n",
    "model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss_list = checkpoint['loss_list']\n",
    "acc_list = checkpoint['train_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ve do thi loss (train, val)\n",
    "def visualize_loss (checkpoint, path_loss):\n",
    "    loss = checkpoint['loss_list'] \n",
    "    train_loss = [x['train_loss'] for x in loss]\n",
    "    valid_loss = [x['valid_loss'] for x in loss]\n",
    "    fig, ax = plt.subplots(figsize = (18, 14.5))\n",
    "    ax.plot(train_loss, '-gx', label='Training loss')\n",
    "    ax.plot(valid_loss , '-ro', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs of Model FEVGG19_bn \",\n",
    "    xlabel='Epoch',\n",
    "    ylabel='Loss')\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    plt.savefig(path_loss)\n",
    "visualize_loss(checkpoint, '../FEVGG19bn/lossFEVGG19_bn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ve do thi acc (train, val)\n",
    "def visualize_acc (checkpoint, path_acc):\n",
    "    acclist = checkpoint['train_acc'] #\n",
    "    train_acc = [x['train_acc'] for x in acclist]\n",
    "    valid_acc = [x['valid_acc'] for x in acclist]\n",
    "    fig, ax = plt.subplots(figsize = (18, 14.5))\n",
    "    ax.plot(train_acc, '-bx', label='Training acc')\n",
    "    ax.plot(valid_acc , '-yo', label='Validation acc')\n",
    "    ax.set(title=\"Accuracy over epochs of Model \",\n",
    "    xlabel='Epoch',\n",
    "    ylabel='Accuracy')\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    plt.savefig(path_acc)\n",
    "visualize_acc(checkpoint, '../FEVGG19bn/AccuracyFEVGG19bn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model\n",
    "def test_loop():\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        for data, target in test_dataloader:\n",
    "            batch_size = data.size(0)\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            _,pred = torch.max(output, 1)\n",
    "            y_true += target.tolist()\n",
    "            y_pred += pred.tolist()\n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "y_true, y_pred = test_loop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "fix, ax = plt.subplots(figsize = (10,10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cnf_matrix, display_labels = classes)\n",
    "disp.plot(include_values = True, cmap = 'viridis_r', ax = ax, xticks_rotation = 'vertical')\n",
    "plt.savefig('../FEVGG19bn/MatrixFEVGG19bn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rp = '../FEVGG19bn/report_FEVGG19bn.txt'\n",
    "try:\n",
    "    s = classification_report(y_true, y_pred, target_names = classes)\n",
    "    with open(path_rp, mode ='x') as f:\n",
    "        f.write(s)\n",
    "    with open(path_rp) as f:\n",
    "        print(f.read())\n",
    "    f.close()\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict images\n",
    "def img_transform(path_img):\n",
    "    img = Image.open(path_img)\n",
    "    imagetensor = test_transform(img).cuda()\n",
    "    return imagetensor\n",
    "\n",
    "def predict(path_img, verbose = False):\n",
    "    if not verbose:\n",
    "        warnings.filterwarnings('ignore')\n",
    "    try:\n",
    "        checks_if_model_is_loaded = type(model)\n",
    "    except:\n",
    "        pass\n",
    "    model.eval()\n",
    "    if verbose:\n",
    "        print('Model loader ...')\n",
    "    image = img_transform(path_img)\n",
    "    image1 = image[None,:,:,:]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_ft(image1)\n",
    "        \n",
    "        _,pred_int = torch.max(outputs.data, 1)\n",
    "        _,top1_idx = torch.topk(outputs.data, 1, dim = 1)\n",
    "        pred_idx = int(pred_int.cpu().numpy())\n",
    "        if pred_idx == 0:\n",
    "            pred_str = str('Negative')\n",
    "            print('img: {} is: {}'.format(os.path.basename(path_img), pred_str))\n",
    "        else:\n",
    "            pred_str = str('Positive')\n",
    "            print('img: {} is: {}'.format(os.path.basename(path_img), pred_str))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_str = str('')\n",
    "path_image = './pred/covid.jpg'\n",
    "\n",
    "img = Image.open(path_image)\n",
    "plt.imshow(img)\n",
    "\n",
    "predict(path_image)\n",
    "plt.title('predict:{}'.format(pred_str))\n",
    "plt.text(5,45,'top {}:{}'.format(1,pred_str), bbox = dict(fc='yellow'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
